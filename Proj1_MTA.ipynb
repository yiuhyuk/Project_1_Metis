{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_turn_all = pd.read_csv('turnstile_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_turn_all.rename(columns={mta_turn_all.columns.values[-1]: 'EXITS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548154, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mta_turn_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove duplicate headers and pickle the file\n",
    "'''\n",
    "\n",
    "def remove_headers(df, header1, save_file):\n",
    "    if save_file == True:\n",
    "        drop_rows = [index for index, val in df.iterrows() if val[header1]==header1]\n",
    "        df.drop(drop_rows, inplace=True)\n",
    "        # open a file, where you ant to store the data\n",
    "        file = open('raw_clean', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(df, file)\n",
    "        # close the file\n",
    "        file.close()\n",
    "    else:\n",
    "        # open a file, where you stored the pickled data\n",
    "        file = open('raw_clean', 'rb')\n",
    "        # dump information to that file\n",
    "        df = pickle.load(file)\n",
    "        # close the file\n",
    "        file.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "Make a dict that maps times to an integer mapping of time of the day (or standardized time of the day).\n",
    "We can remove the non-whole number times or we will end up double counting some entries and exits.\n",
    "'''\n",
    "\n",
    "def standard_time(time_str_in):\n",
    "    time_time = time.strptime(time_str_in, '%H:%M:%S')\n",
    "    if (time_time.tm_min != 0) or (time_time.tm_sec != 0):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # Logic for standardizing the times to be generally consistent and comparable\n",
    "        time1 = time.strptime('22:00:00', '%H:%M:%S')\n",
    "        time2 = time.strptime('02:00:00', '%H:%M:%S')\n",
    "        time3 = time.strptime('06:00:00', '%H:%M:%S')\n",
    "        time4 = time.strptime('10:00:00', '%H:%M:%S')\n",
    "        time5 = time.strptime('14:00:00', '%H:%M:%S')\n",
    "        time6 = time.strptime('18:00:00', '%H:%M:%S')\n",
    "        if (time_time >= time1) or (time_time < time2):\n",
    "            time_str_out = '00:00:00'\n",
    "        elif (time_time >= time2) and (time_time < time3):\n",
    "            time_str_out = '04:00:00'\n",
    "        elif (time_time >= time3) and (time_time < time4):\n",
    "            time_str_out = '08:00:00'\n",
    "        elif (time_time >= time4) and (time_time < time5):\n",
    "            time_str_out = '12:00:00'\n",
    "        elif (time_time >= time5) and (time_time < time6):\n",
    "            time_str_out = '16:00:00'\n",
    "        else:\n",
    "            time_str_out = '20:00:00'\n",
    "        return time_str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548137, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_df = remove_headers(mta_turn_all, 'C/A', save_file=True)\n",
    "turn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning the data\n",
    "'''\n",
    "turn_df['entries_int'] = pd.to_numeric(turn_df['ENTRIES'])\n",
    "turn_df['exits_int'] = pd.to_numeric(turn_df['EXITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_df['standard_time'] = turn_df['TIME'].apply(standard_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean = True\n",
    "\n",
    "if save_clean:\n",
    "    # open a file, where you want to store the data\n",
    "    file = open('raw_mod', 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump(turn_df, file)\n",
    "    # close the file\n",
    "    file.close()\n",
    "else:\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open('raw_mod', 'rb')\n",
    "    # dump information to that file\n",
    "    turn_df = pickle.load(file)\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_of_week(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').weekday()\n",
    "\n",
    "def get_month(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').month\n",
    "\n",
    "def get_day(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').day\n",
    "\n",
    "def get_week(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').isocalendar()[1]\n",
    "\n",
    "# Here is the fix: added LINENAME to groupby\n",
    "station_df = turn_df.groupby(by=['STATION', 'LINENAME', 'DATE','standard_time']).sum()\n",
    "station_df['entries_diff'] = station_df['entries_int'].diff()\n",
    "station_df['exits_diff'] = station_df['exits_int'].diff()\n",
    "station_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine station and line into a unique ID\n",
    "station_df.rename(columns={'STATION': 'station_old'}, inplace=True)\n",
    "station_df['STATION'] = station_df['station_old'] + ' & ' + station_df['LINENAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NaN out the rows where the station is changing as those values do not make sense\n",
    "'''\n",
    "station_chg_index = [i+1 for i, val in enumerate(station_df['STATION'][1:]) if val != station_df['STATION'][i]]\n",
    "for i in station_chg_index:\n",
    "    station_df.loc[i, 'entries_diff'] = np.nan\n",
    "    station_df.loc[i, 'exits_diff'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['day_of_week'] = station_df['DATE'].apply(get_day_of_week)\n",
    "station_df['month'] = station_df['DATE'].apply(get_month)\n",
    "station_df['day'] = station_df['DATE'].apply(get_day)\n",
    "station_df['week'] = station_df['DATE'].apply(get_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan that result from station transition\n",
    "station_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57393 rows dropped from df out of 282948 total\n",
      "165 rows dropped from df out of 225556 total\n"
     ]
    }
   ],
   "source": [
    "# Remove negatives and the row after as well (because there is usually a reversal)\n",
    "\n",
    "def clear_outliers(df, field):\n",
    "    original_len = df.shape[0]\n",
    "    clear_list = list(df[df[field] < 0].index)\n",
    "    clear_list_plus1 = [i+1 for i in clear_list]\n",
    "    clear_list.append(clear_list_plus1)\n",
    "    for i in clear_list:\n",
    "        if i in list(df.index):\n",
    "            df.loc[i, field] = np.nan\n",
    "    df.dropna(inplace=True)\n",
    "    print(str(len(clear_list)) + ' rows dropped from df out of ' + str(original_len) + ' total')\n",
    "    return df, len(clear_list)\n",
    "    \n",
    "station_df, rows_dropped_entries = clear_outliers(station_df, 'entries_diff')\n",
    "station_df, rows_dropped_entries = clear_outliers(station_df, 'exits_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['total_traffic'] = station_df['entries_diff'] + station_df['exits_diff']\n",
    "grp_station_weekday = station_df.groupby(by=['STATION','day_of_week']).mean()['total_traffic']\n",
    "grp_station = station_df.groupby(by=['STATION']).mean()['total_traffic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION\n",
       "42 ST-PORT AUTH & ACENQRS1237W    3.438867e+09\n",
       "34 ST-HERALD SQ & BDFMNQRW        3.297617e+09\n",
       "CANAL ST & JNQRZ6W                2.654531e+09\n",
       "TIMES SQ-42 ST & 1237ACENQRSW     2.250495e+09\n",
       "72 ST & 123                       2.062634e+09\n",
       "57 ST-7 AV & NQRW                 1.817404e+09\n",
       "BAY PKWY & N                      1.667758e+09\n",
       "HIGH ST & AC                      1.601329e+09\n",
       "23 ST & FM                        1.587339e+09\n",
       "LEXINGTON AV/53 & EM6             1.534667e+09\n",
       "23 ST & 6                         1.459766e+09\n",
       "104 ST & JZ                       1.424171e+09\n",
       "FULTON ST & ACJZ2345              1.334671e+09\n",
       "FLATBUSH AV-B.C & 25              1.280317e+09\n",
       "47-50 STS ROCK & BDFM             1.179158e+09\n",
       "183 ST & 4                        1.160948e+09\n",
       "1 AV & L                          1.158351e+09\n",
       "EASTCHSTER/DYRE & 5               1.104071e+09\n",
       "3 AV-149 ST & 25                  1.084647e+09\n",
       "6 AV & FLM123                     1.075920e+09\n",
       "Name: total_traffic, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_station.sort_values(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean = True\n",
    "\n",
    "if save_clean:\n",
    "    # open a file, where you want to store the data\n",
    "    file = open('final', 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump(station_df, file)\n",
    "    # close the file\n",
    "    file.close()\n",
    "else:\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open('final', 'rb')\n",
    "    # dump information to that file\n",
    "    station_df = pickle.load(file)\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
