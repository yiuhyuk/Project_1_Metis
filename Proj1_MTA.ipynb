{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_turn_all = pd.read_csv('turnstile_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_turn_all.rename(columns={mta_turn_all.columns.values[-1]: 'EXITS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548154, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mta_turn_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove duplicate headers and pickle the file\n",
    "'''\n",
    "\n",
    "def remove_headers(df, header1, save_file):\n",
    "    if save_file == True:\n",
    "        drop_rows = [index for index, val in df.iterrows() if val[header1]==header1]\n",
    "        df.drop(drop_rows, inplace=True)\n",
    "        # open a file, where you ant to store the data\n",
    "        file = open('raw_clean', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(df, file)\n",
    "        # close the file\n",
    "        file.close()\n",
    "    else:\n",
    "        # open a file, where you stored the pickled data\n",
    "        file = open('raw_clean', 'rb')\n",
    "        # dump information to that file\n",
    "        df = pickle.load(file)\n",
    "        # close the file\n",
    "        file.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "Make a dict that maps times to an integer mapping of time of the day (or standardized time of the day).\n",
    "We can remove the non-whole number times or we will end up double counting some entries and exits.\n",
    "'''\n",
    "\n",
    "def standard_time(time_str_in):\n",
    "    time_time = time.strptime(time_str_in, '%H:%M:%S')\n",
    "    if (time_time.tm_min != 0) or (time_time.tm_sec != 0):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # Logic for standardizing the times to be generally consistent and comparable\n",
    "        time1 = time.strptime('00:00:00', '%H:%M:%S')\n",
    "        time2 = time.strptime('04:00:00', '%H:%M:%S')\n",
    "        time3 = time.strptime('08:00:00', '%H:%M:%S')\n",
    "        time4 = time.strptime('12:00:00', '%H:%M:%S')\n",
    "        time5 = time.strptime('16:00:00', '%H:%M:%S')\n",
    "        time6 = time.strptime('20:00:00', '%H:%M:%S')\n",
    "        if (time_time >= time1) and (time_time < time2):\n",
    "            time_str_out = '02:00:00'\n",
    "        elif (time_time >= time2) and (time_time < time3):\n",
    "            time_str_out = '06:00:00'\n",
    "        elif (time_time >= time3) and (time_time < time4):\n",
    "            time_str_out = '10:00:00'\n",
    "        elif (time_time >= time4) and (time_time < time5):\n",
    "            time_str_out = '14:00:00'\n",
    "        elif (time_time >= time5) and (time_time < time6):\n",
    "            time_str_out = '18:00:00'\n",
    "        else:\n",
    "            time_str_out = '22:00:00'\n",
    "        return time_str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548137, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_df = remove_headers(mta_turn_all, 'C/A', save_file=True)\n",
    "turn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning the data\n",
    "'''\n",
    "turn_df['entries_int'] = pd.to_numeric(turn_df['ENTRIES'])\n",
    "turn_df['exits_int'] = pd.to_numeric(turn_df['EXITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_df['standard_time'] = turn_df['TIME'].apply(standard_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean = True\n",
    "\n",
    "if save_clean:\n",
    "    # open a file, where you want to store the data\n",
    "    file = open('raw_mod', 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump(turn_df, file)\n",
    "    # close the file\n",
    "    file.close()\n",
    "else:\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open('raw_mod', 'rb')\n",
    "    # dump information to that file\n",
    "    turn_df = pickle.load(file)\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_of_week(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').weekday()\n",
    "\n",
    "def get_month(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').month\n",
    "\n",
    "def get_day(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').day\n",
    "\n",
    "def get_week(date):\n",
    "    return datetime.datetime.strptime(date, '%m/%d/%Y').isocalendar()[1]\n",
    "\n",
    "# Here is the fix: added LINENAME to groupby\n",
    "station_df = turn_df.groupby(by=['STATION', 'LINENAME', 'DATE','standard_time']).sum()\n",
    "station_df['entries_diff'] = station_df['entries_int'].diff()\n",
    "station_df['exits_diff'] = station_df['exits_int'].diff()\n",
    "station_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine station and line into a unique ID\n",
    "station_df.rename(columns={'STATION': 'station_old'}, inplace=True)\n",
    "station_df['STATION'] = station_df['station_old'] + ' & ' + station_df['LINENAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NaN out the rows where the station is changing as those values do not make sense\n",
    "'''\n",
    "station_chg_index = [i+1 for i, val in enumerate(station_df['STATION'][1:]) if val != station_df['STATION'][i]]\n",
    "for i in station_chg_index:\n",
    "    station_df.loc[i, 'entries_diff'] = np.nan\n",
    "    station_df.loc[i, 'exits_diff'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['day_of_week'] = station_df['DATE'].apply(get_day_of_week)\n",
    "station_df['month'] = station_df['DATE'].apply(get_month)\n",
    "station_df['day'] = station_df['DATE'].apply(get_day)\n",
    "station_df['week'] = station_df['DATE'].apply(get_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan that result from station transition\n",
    "station_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970 rows dropped from df out of 339336 total\n",
      "499 rows dropped from df out of 337367 total\n"
     ]
    }
   ],
   "source": [
    "# Remove negatives and the row after as well (because there is usually a reversal)\n",
    "\n",
    "def clear_outliers(df, field):\n",
    "    original_len = df.shape[0]\n",
    "    clear_list = list(df[df[field] < 0].index)\n",
    "    clear_list_plus1 = [i+1 for i in clear_list]\n",
    "    clear_list.append(clear_list_plus1)\n",
    "    for i in clear_list:\n",
    "        if i in list(df.index):\n",
    "            df.loc[i, field] = np.nan\n",
    "    df.dropna(inplace=True)\n",
    "    print(str(len(clear_list)) + ' rows dropped from df out of ' + str(original_len) + ' total')\n",
    "    return df, len(clear_list)\n",
    "    \n",
    "station_df, rows_dropped_entries = clear_outliers(station_df, 'entries_diff')\n",
    "station_df, rows_dropped_entries = clear_outliers(station_df, 'exits_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['total_traffic'] = station_df['entries_diff'] + station_df['exits_diff']\n",
    "grp_station_weekday = station_df.groupby(by=['STATION','day_of_week']).mean()['total_traffic']\n",
    "grp_station = station_df.groupby(by=['STATION']).mean()['total_traffic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION\n",
       "42 ST-PORT AUTH & ACENQRS1237W    2.792975e+07\n",
       "3 AV-149 ST & 25                  2.450819e+07\n",
       "72 ST & 123                       2.266953e+07\n",
       "CANAL ST & JNQRZ6W                1.286192e+07\n",
       "34 ST-HERALD SQ & BDFMNQRW        1.243992e+07\n",
       "125 ST & 456                      1.141896e+07\n",
       "BROOKLYN BRIDGE & 456JZ           1.125392e+07\n",
       "CHAMBERS ST & JZ456               1.099157e+07\n",
       "190 ST & A                        1.011854e+07\n",
       "1 AV & L                          1.004532e+07\n",
       "COURT SQ & EMG                    9.003206e+06\n",
       "BAY PKWY & N                      8.706366e+06\n",
       "125 ST & 23                       8.534066e+06\n",
       "59 ST & NRW                       7.562403e+06\n",
       "18 AV & F                         7.522464e+06\n",
       "183 ST & 4                        7.517503e+06\n",
       "KINGS HWY & BQ                    7.088618e+06\n",
       "225 ST & 25                       7.020078e+06\n",
       "FLATBUSH AV-B.C & 25              6.861365e+06\n",
       "FRANKLIN AV & 2345S               6.744224e+06\n",
       "Name: total_traffic, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_station.sort_values(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean = True\n",
    "\n",
    "if save_clean:\n",
    "    # open a file, where you want to store the data\n",
    "    file = open('final', 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump(station_df, file)\n",
    "    # close the file\n",
    "    file.close()\n",
    "else:\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open('final', 'rb')\n",
    "    # dump information to that file\n",
    "    station_df = pickle.load(file)\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
